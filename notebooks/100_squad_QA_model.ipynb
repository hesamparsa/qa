{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cf7d3113",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "yes | conda create -n ml python=3.8.5 -c conda-forge\n",
    "source activate ml\n",
    "cd SageMaker/udemy_nlp\n",
    "yes | pip install -r requirements.txt\n",
    "conda install pytorch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0 cudatoolkit=10.1 -c pytorch\n",
    "yes | pip install jupyter\n",
    "python -m ipykernel install --user --name ml --display-name \"ML\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "72f18d9f",
   "metadata": {},
   "source": [
    "elasticsearch==7.10.0\n",
    "farm-haystack==0.7.0\n",
    "kaggle==1.5.12\n",
    "nltk==3.5\n",
    "numpy==1.19.2\n",
    "pandas==1.1.5\n",
    "rouge==1.0.0\n",
    "seaborn==0.11.1\n",
    "transformers==4.1.1\n",
    "sentence-transformers==1.1.0\n",
    "spacy==3.0.6\n",
    "spacy-transformers==1.0.2\n",
    "flair==0.8\n",
    "tensorflow==2.5.1\n",
    "ipykernel==5.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb9c48",
   "metadata": {},
   "source": [
    "## SQuAD 2.0 Dataset\n",
    "The SQuAD (Stanford Question and Answering Dataset) is a hugely popular dataset containing question and answer pairs scraped from Wikipedia, covering topics ranging from Beyonce, to Physics. As one of the most comprehensive Q&A datasets available, it's only natural that we will be making use of it. So let's explore it.\n",
    "\n",
    "First, we'll need to download the data. There are two JSON files that we are interested in - train and dev, which we can downloaded from http. Here we will be storing the SQuAD data in the ../../data/squad directory, so we must check if this already exists and if not create the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f209ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "squad_dir = 'data/squad'\n",
    "\n",
    "if not os.path.exists(squad_dir):\n",
    "    os.mkdir(squad_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "209b2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'\n",
    "files = ['train-v2.0.json', 'dev-v2.0.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921ca286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "for file in files:\n",
    "    res = requests.get(url+file)\n",
    "    # write to file in chunks\n",
    "    with open(os.path.join(squad_dir, file), 'wb') as f:\n",
    "        for chunk in res.iter_content(chunk_size=40):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e457c7b",
   "metadata": {},
   "source": [
    "Now that we have both files stored locally, lets open up the training data and see what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bbd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(squad_dir, 'train-v2.0.json'), 'rb') as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92aade",
   "metadata": {},
   "source": [
    "The JSON structure contains a top-level 'data' key which contains a list of groups, where each group is a topic, such as Beyonce, Chopin, or Matter. We can take a look at the first and last groups respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77722fe",
   "metadata": {},
   "source": [
    "We'll work through parsing this data into a cleaner format that we will be using in later notebooks. We need to create a format that consists of a list of dictionaries where each dictionary contains a single question, answer, and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0949080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list where we will place all of our data\n",
    "new_squad = []\n",
    "\n",
    "# we need to loop through groups -> paragraphs -> qa_pairs\n",
    "for group in squad['data']:\n",
    "    for paragraph in group['paragraphs']:\n",
    "        # we pull out the context from here\n",
    "        context = paragraph['context']\n",
    "        for qa_pair in paragraph['qas']:\n",
    "            # we pull out the question\n",
    "            question = qa_pair['question']\n",
    "            # now the logic to check if we have 'answers' or 'plausible_answers'\n",
    "            if 'answers' in qa_pair.keys() and len(qa_pair['answers']) > 0:\n",
    "                answer = qa_pair['answers'][0]['text']\n",
    "            elif 'plausible_answers' in qa_pair.keys() and len(qa_pair['plausible_answers']) > 0:\n",
    "                answer = qa_pair['plausible_answers'][0]['text']\n",
    "            else:\n",
    "                # this shouldn't happen, but just in case we just set answer = None\n",
    "                answer = None\n",
    "            # append dictionary sample to parsed squad\n",
    "            new_squad.append({\n",
    "                'question': question,\n",
    "                'answer': answer,\n",
    "                'context': context\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1df2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'When did Beyonce start becoming popular?',\n",
       "  'answer': 'in the late 1990s',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'},\n",
       " {'question': 'What areas did Beyonce compete in when she was growing up?',\n",
       "  'answer': 'singing and dancing',\n",
       "  'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_squad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3440efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e018a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(squad_dir, 'train.json'), 'w') as f:\n",
    "    json.dump(new_squad, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59bf6ba",
   "metadata": {},
   "source": [
    "## QA Model\n",
    "For our first QA model we will setup a simple question-answering pipeline using HuggingFace transformers and a pretrained BERT model. We will be testing it on our SQuAD data so let's load that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf4f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/squad/train.json', 'r') as f:\n",
    "    squad = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "237185f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d5951001c449f0a85d2b9d99e7b972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c13a3ffca3f44fab26e64400404409e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbab43e7a1ab4591bdf18af237e1b91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a3a57ba39a47919b378326620065d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21546c4da9d416e8f3ff33a86bd1bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "\n",
    "modelname = 'deepset/bert-base-cased-squad2'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(modelname)\n",
    "model = BertForQuestionAnswering.from_pretrained(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9a931",
   "metadata": {},
   "source": [
    "Transformers comes with a useful class called pipeline which allows us to setup easy to use pipelines for common architectures.\n",
    "\n",
    "One of those pipelines is the question-answering pipeline which allows us to feed a dictionary containing a 'question' and 'context' and return an answer. Which we initialize like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03787ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa = pipeline('question-answering', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ad2adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted': 'late 1990s', 'true': 'in the late 1990s'},\n",
       " {'predicted': 'singing and dancing', 'true': 'singing and dancing'},\n",
       " {'predicted': '(2003),', 'true': '2003'},\n",
       " {'predicted': 'Houston, Texas,', 'true': 'Houston, Texas'},\n",
       " {'predicted': '1990s', 'true': 'late 1990s'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will intialize a list for answers\n",
    "answers = []\n",
    "\n",
    "for pair in squad[:5]:\n",
    "    # pass in our question and context to return an answer\n",
    "    ans = qa({\n",
    "        'question': pair['question'],\n",
    "        'context': pair['context']\n",
    "    })\n",
    "    # append predicted answer and real to answers list\n",
    "    answers.append({\n",
    "        'predicted': ans['answer'],\n",
    "        'true': pair['answer']\n",
    "    })\n",
    "answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ml",
   "language": "python",
   "name": "conda_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
